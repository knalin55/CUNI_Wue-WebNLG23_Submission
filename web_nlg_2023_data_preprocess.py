# -*- coding: utf-8 -*-
"""web-nlg-2023-data-preprocess.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GGc-OL8fMjX4h-KIBBirkoHk9HEMmICQ
"""


#!git clone https://gitlab.com/webnlg/corpus-reader.git

import os 
import re
import random
from benchmark_reader import Benchmark, select_files
from collections import Counter

def process_triples(fil_dir, data_split="train", languages=["ga"]):

    triples_list    = []
    text_list       = []
    lang_list       = []


    for lang in languages:

        data_path = os.path.join(fil_dir, f"{lang}_{data_split}.xml")

        b = Benchmark()
        files = select_files(data_path)
        b.fill_benchmark(files)
        
        entry_list = [entry for entry in b.entries]
    
        random.shuffle(entry_list)

        for entry in entry_list:
            for text in entry.lexs[-len(entry.lexs)//2:]:
                triples_list.append(entry.list_triples())
                text_list.append(text.lex)
                lang_list.append(lang)

    
    return {"triple":triples_list, "text":text_list, "lang": lang_list}

#data_train = process_triples(fil_dir,"train", languages=['mt'])

def create_df(data):
  RDF = list(data['triple'])
  text = list(data['text'])
  lang = list(data['lang'])
  tups_data = list()
  for i, j , k in zip(RDF, text, lang):
    i = ' $ '.join(i)

    tups_data.append((i,j,k))
  
  df = pd.DataFrame(tups_data, columns=['triple', 'text', 'language'])

  return df

langs = ['mt', 'cy','br','ru','ga']
splits = ['train','dev']
fil_dir = '/content/drive/MyDrive/2023-Challenge/data'
for l in langs:
  for s in splits:
    dataset = process_triples(fil_dir, s, languages=[l])
    df_split = create_df(dataset)
    df_split.to_csv(f'{write_path}/{l}_{l}_{s}.tsv', sep='\t', index=False)
    df_split.to_csv(f'{write_path}/{l}_{l}_{s}.csv', sep=',', index=False)